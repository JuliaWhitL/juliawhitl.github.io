[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Tidy Tuesday: James Beard Award\n\n\n\n\n\n\ntidy\n\n\n\nLooking at data in the Tidy Tuesday challenge for Dec 31, 2024\n\n\n\n\n\n12/31/24\n\n\nJulia Whitman\n\n\n\n\n\n\n\n\n\n\n\n\nProperties of variance estimators\n\n\n\n\n\n\nR\n\n\nvariance\n\n\nglms\n\n\n\nA look at their bias and stability under three data generating mechanisms\n\n\n\n\n\n7/15/24\n\n\nJulia Whitman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Julia Whitman",
    "section": "",
    "text": "Hi there! I’m a biostatistician moonlighting as a data scientist. I love using statistics, visualizations, and common sense to help answer technical questions of all kinds and communicating with diverse audiences."
  },
  {
    "objectID": "posts/2024-12-04-thesis-presentation/index.html",
    "href": "posts/2024-12-04-thesis-presentation/index.html",
    "title": "Properties of variance estimators",
    "section": "",
    "text": "The purpose of this study is to explore the behavior of several commonly used variance estimators under different data generating mechanisms (DGMs). In particular we focus on the variance of the variance estimator (the “stability”) and describe the relative trade-offs as they relate to bias and stability.\n\n\n\nLikelihood-based Poisson estimator yielded the most stable SE estimates\nRobust methods had the largest variability, making them the least stable\nTrade-off of loosening parametric assumptions included lower stability and greater bias under DGMs explored here\n\n\n\n\n\nChapter 1: Statistical background; models & derivations\nChapter 2: Simulations\nChapter 3: Application to FAMS\nChapter 4: Conclusion"
  },
  {
    "objectID": "posts/2024-12-04-thesis-presentation/index.html#summary-of-findings",
    "href": "posts/2024-12-04-thesis-presentation/index.html#summary-of-findings",
    "title": "Properties of variance estimators",
    "section": "",
    "text": "Likelihood-based Poisson estimator yielded the most stable SE estimates\nRobust methods had the largest variability, making them the least stable\nTrade-off of loosening parametric assumptions included lower stability and greater bias under DGMs explored here"
  },
  {
    "objectID": "posts/2024-12-04-thesis-presentation/index.html#outline",
    "href": "posts/2024-12-04-thesis-presentation/index.html#outline",
    "title": "Properties of variance estimators",
    "section": "",
    "text": "Chapter 1: Statistical background; models & derivations\nChapter 2: Simulations\nChapter 3: Application to FAMS\nChapter 4: Conclusion"
  },
  {
    "objectID": "posts/2024-12-04-thesis-presentation/index.html#generalized-linear-models",
    "href": "posts/2024-12-04-thesis-presentation/index.html#generalized-linear-models",
    "title": "Properties of variance estimators",
    "section": "Generalized Linear Models",
    "text": "Generalized Linear Models\nGeneralized linear models (GLMs) “generalize” linear regression for exponential family distributions. They increase model flexibility by:\n\nTransforming the mean using “link” function - allows function of the response to vary linearly with the predictors\nDefining a mean-variance relationship\n\n\nApproaches to variance estimation using GLMs\n\nLikelihood-based methods often used because of mathematical appeal and simplicity\nRigid assumptions are often unrealistic when working with real-world data, which can lead to invalid inference.\nRobust estimation methods limit effect of some violations on parameter estimation, especially mean-variance misspecification\nExamples include:\n\nHuber-White sandwich variance\nBootstrap methods (nonparametric)\n\n\n\n\nFocus of this work\n“What are the trade-offs of using more flexible methods?”\n\nFigure 1: A simulated illustration of variance estimator instability. The variance in the scenario on the left is stable, producing CIs of equal length. The variance in the scenario on the right is ”unstable” by contrast, and produces CIs of varying lengths."
  },
  {
    "objectID": "posts/2024-12-04-thesis-presentation/index.html#estimator-validity",
    "href": "posts/2024-12-04-thesis-presentation/index.html#estimator-validity",
    "title": "Properties of variance estimators",
    "section": "Estimator validity",
    "text": "Estimator validity\nTable 1. Validity of variance estimators under three data generating mechanisms \n\nFigure 2. Probability densities under Poisson \\((\\lambda = 2)\\), quasi-Poisson \\((\\lambda = 2, \\phi = 2)\\), and negative binomial \\((\\mu = 2, \\phi = 2)\\) frameworks. These discrete distributions are presented continuously to visualize differences in density and dispersion."
  },
  {
    "objectID": "posts/2024-12-04-thesis-presentation/index.html#derivations",
    "href": "posts/2024-12-04-thesis-presentation/index.html#derivations",
    "title": "Properties of variance estimators",
    "section": "Derivations",
    "text": "Derivations\nFirst specified a GLM and defined the mean model and mean-variance relationship. We did this using a Poisson distribution with the mean model defined through a log link.\nThe Poisson density is re-written in canonical form, where the natural parameter is \\(\\theta = log(\\lambda)\\) and scale parameter is \\(\\phi = 1\\). Our mean model is defined as \\(g(E[Y]) = g(\\mu) = g(b'(\\theta)) = log(\\theta)\\):\n\\[\nf(Y|x;\\theta,\\phi) = exp\\Bigg[\\frac{y\\theta(x^T\\beta) - b(\\theta(x^T\\beta))}{\\phi} + c(y, \\phi)\\Bigg]\n\\] \\[f(y|\\lambda) = \\frac{\\lambda^ye^{-\\lambda}}{y!}\\] \\[=exp\\bigg[ylog(\\lambda) - \\lambda - log(y!)\\bigg]\\]\nScore equations used to estimate parameters via maximum likelihood estimation\n\\[D^TV^{-1}(y-\\mu) = X^T(y-exp(X\\beta)) = 0\\]\nAsymptotically, it can be shown that the distribution of \\(\\beta\\) is:\n\\[\\widehat{\\beta_N} \\sim N \\Bigg( \\beta_0, \\frac{1}{N} \\big[A_N(\\beta_0) \\big]^{-1}B(\\beta_0) \\big[A_N(\\beta_0) \\big]^{-1}\\Bigg)\\]\n\n\\(A_N = A_N^{obs}(\\widehat{\\beta}) = X^T diag(exp(x_i^T \\eta) (1-exp(x_i^T \\beta)))X = X^T V(\\beta)X\\)\n\\(B_N^{obs} (\\widehat{\\beta})= \\sum_{i=1}^N G(\\beta;x_i,Y_i )\\times G(\\beta;,x_i,Y_i )^T =D^T (\\beta) V^{-1} (\\beta)diag(Y_i- \\mu_i (\\beta))^2 V^{-1} (\\beta)D(\\beta)\\)\n\nFinally, \\(\\phi\\) estimated to use in quasi-Poisson variance estimation:\n\\[\\widehat{\\phi} = \\frac{1}{N-K}\\sum_{i=1}^N \\frac{(y_i-\\widehat{\\mu}_i)^2}{V(\\widehat{\\mu_i})}\\]\n\\[ = \\frac{1}{N-K}\\sum_{i=1}^N \\frac{(y_i-exp(x_i^T\\widehat{\\beta}))^2}{exp(x_i^T\\widehat{\\beta})}\\]\nThe six variance estimators are constructed as follows:\n\nPoisson\n\\[\\widehat{Cov}[\\widehat{\\beta}] = A_N^{-1}(\\beta)\\]\nQuasi-Poisson\n\\[\\widehat{Cov}[\\widehat{\\beta}] = \\widehat{\\phi} \\times A_N^{-1}(\\beta)\\]\nSandwich\n\\[\\widehat{Cov}[\\widehat{\\beta}] = A_N^{-1}(\\beta)\\bigg( B_N^{obs}(\\widehat{\\beta})\\bigg)A_N^{-1}(\\beta)\\]\nUnconditional bootstrap\n\nWith-replacement sampling with 500 bootstrap replicates conducted over the entire dataset to produce point estimates and SEs.\n\nConditional bootstrap\n\nWith-replacement sampling with 500 bootstrap replicates conducted from within subsets of the data for each X indicator to produce point estimates and SEs.\n\nNegative Binomial\n\n\nAssumed mean-variance relationship: \\[Var[Y_i|x_i] = \\mu_i + \\frac{\\mu_i^2}{\\phi}\\]\nEstimating equations: \\[D^T (\\beta) V^{-1} (\\beta,\\phi)(y-\\mu(\\beta))=0\\]"
  },
  {
    "objectID": "posts/2024-12-04-thesis-presentation/index.html#estimator-bias",
    "href": "posts/2024-12-04-thesis-presentation/index.html#estimator-bias",
    "title": "Properties of variance estimators",
    "section": "Estimator bias",
    "text": "Estimator bias\nThe average bias of each estimator was computed as a percentage of the ESE. The majority of estimators displayed “negative bias”, resulting in an underestimate of the true variance and overstated certainty of the true parameter value.\n\nFigure 4. Average bias of SE estimators as a proportion of ESE in the Poisson framework.\n\nLower bias as sample sizes increase\nThe two bootstrap estimators demonstrate the greatest bias across sample sizes, except in N=1,280\n\n\nFigure 5. Average bias of SE estimators as a proportion of the ESE in the quasi-Poisson framework.\n\nThe Poisson estimator is highly biased compared to all other estimators.\nBias decreases overall in non-Poisson estimators as sample sizes increase, but trend is inconsistent\n\n\nFigure 6. Average bias of SE estimators as a proportion of the ESE in the negative binomial framework.\n\nThe Poisson estimator is highly biased compared to all other estimators.\nBootstrap and sandwich estimators exhibit more bias than other non-Poisson estimators at smaller sample sizes.\nMost estimators are more biased at smaller samples compared to quasi-Poisson scenario\nConsistent downward trajectory with increasing sample sizes"
  },
  {
    "objectID": "posts/2024-12-04-thesis-presentation/index.html#estimator-stability",
    "href": "posts/2024-12-04-thesis-presentation/index.html#estimator-stability",
    "title": "Properties of variance estimators",
    "section": "Estimator stability",
    "text": "Estimator stability\nThe stability of each estimator was illustrated using the SD of the estimated SE.\n\nFigure 7. SD of the estimated SE over finite sample sizes\n\nLikelihood-based Poisson estimator was the most stable (smallest SD of estimated SE) under Poisson, quasi-Poisson and negative binomial frameworks\nQuasi-Poisson and negative binomial estimators had comparable performance\nRobust estimators had lowest stability with similar patterns\n\n\nFigure 8. Ratio of individual model SD of the estimated SE to Poisson model SE of the estimated SE\n\nQuasi-Poisson and negative binomial performed similarly with constant ratios at N&gt;160\nSandwich reached constant at higher ratio in scenarios A and B\nBootstrap estimators had largest SD of SE ratios and failed to level off\n\n\nFigure 9. Ratio of individual model SDvof the estimated SE to the ”correct” model SE of the estimated SE for each respective framework\n\nPoisson was the denominator in scenario A\nQuasi-Poisson denominator in scenario B\nNegative binomial denominator in scenario C\n\nNegative binomial variance estimator was most stable in scenario B. Meanwhile, the sandwich had lower stability, and bootstrap estimators performed similarly as in the prior example."
  },
  {
    "objectID": "posts/2024-12-04-thesis-presentation/index.html#eligibility",
    "href": "posts/2024-12-04-thesis-presentation/index.html#eligibility",
    "title": "Properties of variance estimators",
    "section": "Eligibility",
    "text": "Eligibility\n\nDiagnosis of Type II diabetes mellitus (T2DM)\nAt least one daily diabetes medication\nAged 18-75 years\nEnglish-speaking\nCommunity-dwelling\nOwned mobile phone"
  },
  {
    "objectID": "posts/2024-12-04-thesis-presentation/index.html#trial-procedures",
    "href": "posts/2024-12-04-thesis-presentation/index.html#trial-procedures",
    "title": "Properties of variance estimators",
    "section": "Trial procedures",
    "text": "Trial procedures\n\nRandomization was 1:1 to intervention or control\nIntervention included monthly coaching sessions for the person with T2DM, text message support, and optional text messages to their designated support person.\nAll participants received printed material on diabetes management and access to on-study HbA1c"
  },
  {
    "objectID": "posts/2024-12-04-thesis-presentation/index.html#study-cohort",
    "href": "posts/2024-12-04-thesis-presentation/index.html#study-cohort",
    "title": "Properties of variance estimators",
    "section": "Study cohort",
    "text": "Study cohort\nPerformance of our six variance estimators was studied in a subset of the FAMS dataset. Participants were included if they had complete data for:\n\nText message responses (participant “engagement”)\nNumber of texts received (offset)\nAge\nRace/ethnicity\nGender\nEducation\nIncome\nInsurance\nBaseline physical activity *\n\nTable 2. FAMS physical activity groups"
  },
  {
    "objectID": "posts/2024-12-04-thesis-presentation/index.html#variance-estimation",
    "href": "posts/2024-12-04-thesis-presentation/index.html#variance-estimation",
    "title": "Properties of variance estimators",
    "section": "Variance estimation",
    "text": "Variance estimation\n\\(\\beta\\) and SE estimates calculated treating physical activity categorically and continuously\nTable 3. Estimates of \\(\\beta_1\\) and SE for physical activity group, treated categorically\n\nTable 4. Estimates of \\(\\beta_1\\) and SE for physical activity group, treated continuously"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Julia Whitman",
    "section": "",
    "text": "I’m a data scientist at Meta where I study generative AI tools. I currently live in Seattle, WA with my husband, daughter and Billie, our neurotic Beagle rescue.\nA little bit about how I got here. In 2024 I completed my MS in biostatistics at Vanderbilt University, where I also worked as a statistician on the ACTIV6 trial. My research focused on the relative merits of different variance estimators. I spent some years before that working in cancer research as a data manager (2019-2021) and trials coordinator (2017-2019), studying colorectal and neuroendocrine cancers. I graduated from Imperial College London with a degree in epidemiology (2014), and was also an editor and bartender in a past life."
  },
  {
    "objectID": "posts/2024-12-31-tt-beard/index.html",
    "href": "posts/2024-12-31-tt-beard/index.html",
    "title": "Tidy Tuesday: James Beard Award",
    "section": "",
    "text": "Explore the data, watching out for interesting relationships. We would like to emphasize that you should not draw conclusions about causation in the data. There are various moderating variables that affect all data, many of which might not have been captured in these datasets. As such, our suggestion is to use the data provided to practice your data tidying and plotting techniques, and to consider for yourself what nuances might underlie these relationships.\nCreate a visualization, a model, a shiny app, or some other piece of data-science-related output, using R or another programming language.\nShare your output and the code used to generate it on social media with the #TidyTuesday hashtag."
  },
  {
    "objectID": "posts/2024-12-31-tt-beard/index.html#how-have-the-subcategories-of-the-various-awards-changed-over-time",
    "href": "posts/2024-12-31-tt-beard/index.html#how-have-the-subcategories-of-the-various-awards-changed-over-time",
    "title": "Tidy Tuesday: James Beard Award",
    "section": "1. How have the subcategories of the various awards changed over time?",
    "text": "1. How have the subcategories of the various awards changed over time?\nLet’s start by looking at the winners and nominees for the James Beard book awards…\n\n\n\n\n\n\nYikes! Too many categories makes this impossible to read. Let’s group like-categories…\n\n\n\n\n\n\nStill a lot, but better. We can see that the pool of nominees is more varied now than it was in the 1970s and 80s. Some categories, like “simple” books for the home cook and books for healthy eating, have maintained their popularity while technical and general “entertainment” cookbooks have become less so. We also see a gap in the data in 2021 due to the COVID-19 pandemic.\nNow let’s take a look at some of the other award categories, like Broadcast Media and Journalism. We can use the same process as above to combine similar groups and look at how their popularity has evolved over time."
  },
  {
    "objectID": "posts/2024-12-31-tt-beard/index.html#has-anybody-won-in-multiple-categories",
    "href": "posts/2024-12-31-tt-beard/index.html#has-anybody-won-in-multiple-categories",
    "title": "Tidy Tuesday: James Beard Award",
    "section": "2. Has anybody won in multiple categories?",
    "text": "2. Has anybody won in multiple categories?"
  },
  {
    "objectID": "posts/2024-12-31-tt-beard/index.html#which-restaurants-have-the-most-winners-which-newspapers-or-networks",
    "href": "posts/2024-12-31-tt-beard/index.html#which-restaurants-have-the-most-winners-which-newspapers-or-networks",
    "title": "Tidy Tuesday: James Beard Award",
    "section": "3. Which restaurants have the most winners? Which newspapers or networks?",
    "text": "3. Which restaurants have the most winners? Which newspapers or networks?\nFinally, let’s take a look at the biggest winners in the restaurant world.\nIt looks like some of the cities got put in the “restaurant” column. Let’s fix that…"
  }
]